{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBzYfaB4PZPg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from google.colab import files \n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSCoBaDTtmRt"
   },
   "outputs": [],
   "source": [
    "def my_ceil(predictions):\n",
    "  for i in range(len(predictions)):\n",
    "    if predictions[i]%1<=0.5:\n",
    "      predictions[i] = int(predictions[i])\n",
    "    else:\n",
    "      predictions[i] = int(predictions[i]) + 1\n",
    "  return predictions\n",
    "\n",
    "#Export function \n",
    "def export( data_test, predictions):\n",
    "  result_ = pd.DataFrame({'ID': data_test.ID, 'Score': my_ceil(predictions)}) \n",
    "  result_.to_csv('results_.csv', index = False) \n",
    "  \n",
    "  files.download('results_.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "az5e1GHTXory"
   },
   "source": [
    "# Upload preprocessed dataset train and test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKkL-y3YPrR0"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('https://raw.githubusercontent.com/nisrineha/Challenge_data_well_being_at_work/master/datasets/data_test_processed_holiday.csv')\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/nisrineha/Challenge_data_well_being_at_work/master/datasets/data_train_processed_holiday.csv')\n",
    "test_with_ID = pd.read_csv('https://raw.githubusercontent.com/nisrineha/Challenge_data_well_being_at_work/master/datasets/test_input.csv')\n",
    "test_with_date= pd.read_csv('https://raw.githubusercontent.com/nisrineha/Challenge_data_well_being_at_work/master/datasets/train_input.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFlYVL4oASD2"
   },
   "source": [
    "Creation of features and the target variable Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2J_4wJiWh0B"
   },
   "outputs": [],
   "source": [
    "y= train['Score']\n",
    "train1= train\n",
    "train1= train1.drop('Score', axis= 1)\n",
    "X= train1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NH8zJZObAaQd"
   },
   "source": [
    "Spliting of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoQZmsKnXafK"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y , test_size= 0.2, random_state= 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TxVfKGxFAo_4"
   },
   "source": [
    "##Pipeline method\n",
    "\n",
    "Implement of pipeline method using different transformer: numeric and categorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfqfMj1LX04Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "#SimpleImputer fill any missing values \n",
    "#Scaler numeric transformer\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "#One hot encoder to transform categorial values into integers.\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9PX7wPPhA5AN"
   },
   "source": [
    "Transform the categorical features and numeric on train dataset and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vVyO15mFaVj8"
   },
   "outputs": [],
   "source": [
    "#Select les columns numeric \n",
    "#Select les columns categoric \n",
    "\n",
    "\n",
    "integer_features = list(X.columns[X.dtypes == 'int64'])\n",
    "continuous_features = list(X.columns[X.dtypes == 'float64'])\n",
    "categorical_features = list(X.columns[X.dtypes == 'object'])\n",
    "numeric_features = integer_features + continuous_features \n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "integer_features_test = list(test.columns[test.dtypes == 'int64'])\n",
    "continuous_features_test = list(test.columns[test.dtypes == 'float64'])\n",
    "categorical_features_test = list(test.columns[test.dtypes == 'object'])\n",
    "numeric_features = integer_features + continuous_features \n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXp06ue8C5v9"
   },
   "source": [
    "##Model selection\n",
    "In this section, we chose different classifier from sklearn, to get the best classifier for our dataset, we calculate the score thanks to the splitting of the dataset that we did before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "id": "fYbUZuK4dmgv",
    "outputId": "f1affb63-d434-4029-f482-cf8615357ccb"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HistGradientBoostingClassifier' from 'sklearn.ensemble' (C:\\Users\\Nisrine\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9e9a49545e9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNuSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHistGradientBoostingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminant_analysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'HistGradientBoostingClassifier' from 'sklearn.ensemble' (C:\\Users\\Nisrine\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators= 400, max_depth=20),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    HistGradientBoostingClassifier(max_iter=10) \n",
    "   \n",
    "    ]\n",
    "pipes= []\n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', classifier)])\n",
    "    pipe.fit(X_train, y_train)  \n",
    "    pipes.append(pipe) \n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ond68ECdKMQF"
   },
   "source": [
    "From the results above, we observe that the best classifiers are **GradientBoostingClassifier** and  **RandomForestClassifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3R1KkKxwKd4N"
   },
   "source": [
    "we chose GradientBoostingClassifier for submission, we had our best score which is **0,6990**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvQQvpO1tHms"
   },
   "outputs": [],
   "source": [
    "x = test\n",
    "y_pred= pipes[-3].predict(x)\n",
    "export(test_with_ID, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ToDffyOoKrC7"
   },
   "source": [
    "## Using pipeline in GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "gq58YmiVdtff",
    "outputId": "24ba3f72-50d0-4a2d-cc28-79ac6415267a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__criterion': 'entropy', 'classifier__max_depth': 10, 'classifier__max_features': 'auto', 'classifier__n_estimators': 400}\n",
      "0.71359375\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "    'classifier__n_estimators': [ 200, 300,  400, 500],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'classifier__max_depth' : [10, 20, 25, 30],\n",
    "    'classifier__criterion' :['gini', 'entropy']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "CV = GridSearchCV(rf, param_grid, n_jobs= 1)\n",
    "                  \n",
    "CV.fit(X_train, y_train)  \n",
    "print(CV.best_params_)    \n",
    "print(CV.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZwnrKZrLQnb"
   },
   "source": [
    "we had from our grid search our best max depth and number of estimators for our randomforset model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCnjuP6Laltv"
   },
   "outputs": [],
   "source": [
    "#Fitting the classifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(n_estimators= 400, max_depth=20))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "7yAV5FXeazI9",
    "outputId": "a848592e-4619-46bd-b26d-f01306e10929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "                              store_covariance=False, tol=0.0001)\n",
      "model score: 0.734\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train, y_train )\n",
    "\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                  ('classifier',RandomForestClassifier(n_estimators= 400, max_depth=20) )])\n",
    "pipe.fit(X_train, y_train)  \n",
    "print(classifier)\n",
    "print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
    "x = test\n",
    "y_pred= pipe.predict(x)\n",
    "export(test_with_ID, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXusCw5aMEm2"
   },
   "source": [
    "We submitted our results, but we had a score less than the one when we implemented **GradientBoostingClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "yaH1MNUAyWiq",
    "outputId": "2c605788-fae1-41b7-dae7-c508325f335b"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-96e01fb88efb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python3 -m pip install scikit.ensemble\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " pip install scikit.ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Fr7ra2tkJ6L"
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "clf = HistGradientBoostingClassifier(max_iter=10).fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PipeLine.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
